\documentclass{report}
\usepackage{cite}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\begin{document}

 \include{thesisfront}  
 
  \section*{Abstract}
% Do not forget to check each reference while importing in your Bibtex file.
% Especially, IEEExplore export may lead to ill-formatted conference name like \emph{Robotics and Automation, 
% IEEE International Conference on}.
\par An Internet company - Baidu is working on the autonomous driving, they have introduced a local path planning algorithm - expectation maximum planner(EM planner), this is a sampling-based algorithm. We hope to apply this algorithm to AGV cars to achieve the purpose of automatic delivery.\\
\indent
Compared with AGV cars, autonomous vehicles have higher requirements for various algorithms. Autonomous vehicles need to face more complex road environments, and they must be able to respond quickly when driving at high speeds.
We can apply the algorithm to the AGV cars, but considering the cost of logistics robots, their motherboards have lower computing capability, if we use the exhaustive search approach (brute-forced search), the EM planner can always make an ideal choice based on the cost function. However, due to the limited computing capability of the motherboard, we need to adopt appropriate strategies to make the right behavior quickly and well.\\
\indent
The objective of this bibliography report is to present the state-of-the-art work on EM planner, with focus on details of algorithm implementation.


 \newpage
 
 \section*{Acknowledgements}
 First of all, I would like to thank Prof. Olivier Kermorgant agreed to my request to return to China for internship. \\
 \indent
 I am thankful to the Meituan can give me a great opportunity to work on a topic of my interest.
 
 \newpage
 
 \section*{Notations}
 \begin{tabular}{ll}
 $\Omega$ & The 3D space-time\\
  S & Statement\\
 $\mathcal V$ & Vehicle\\
 $\mathcal R$ & 3D Space\\
 $\mathcal O$ & Obstacle\\
 $\tau$ & Collision Test
 \end{tabular}
  \newpage
  \section*{Abbreviations}
  \begin{tabular}{ll}
  EM Planner  & Expectation Maximum Planner\\
  AGV & Automated Guided Vehicle\\
  MP  & Motion Planning\\
  DP & Dynamic Programming\\
  E-step & SL and ST Mapping\\
  M-step & Dynamic Programming of Speed and Path
  
  \end{tabular}
  
 
 \newpage
 
 \listoffigures
 
%\listoftables
 
 \tableofcontents
 
 
 \chapter*{Introduction}
 \addcontentsline{toc}{chapter}{Introduction}	 
 Autonomous driving research began in the 1980s and has significantly grown over the past ten years. Autonomous driving aims to reduce road fatalities, increase traffic efficiency and provide convenient travel. However, autonomous driving is a challenging task that requires accurately sensing the environment, a deep understanding of vehicle intentions and safe driving under different scenarios.\\
 \indent
 The HD map module provides a
 high-definition map that can be accessed by every online module. Perception and localization modules provide the necessary dynamic environment information, which can be further used to predict future environment status in the prediction module. The motion planning module considers all information to generate a safe and smooth trajectory to feed into the vehicle control module.\\
 \indent
 In motion planner, safety is always the top priority. We consider autonomous driving safety in, but not limited to, the following aspects: traffic regulations, range coverage, cycle time efficiency and emergency safety. Even in the area of logistics robots, we need also to consider this. All these aspects are critical. Traffic regulations are designed by governments for public transportation safety, and such regulations also apply to autonomous driving vehicles. An autonomous driving vehicle should follow traffic regulations at all times. For range coverage, we aim to provide a trajectory with at least an eight second or two hundred meter motion planning trajectory. The reason is to leave enough room to maintain safe driving within regular autonomous driving vehicle dynamics. The execution time of the motion planning algorithm is also important. In the case of an emergency, the system could react within 100 ms,compared with a 300 ms reaction time for a normal human driver.
 A safety emergency module is the last shell for protecting the safety of riders. For a level-4 motion planner, once upstream modules can no longer function normally, the safety module within the motion planner shall respond with an immediate emergency behavior and send warnings that interrupt humans. Moreover, the autonomous driving system shall have the ability to react to emergencies in a lower-level-like control module.Further safety design is beyond this manuscript’s
 scope. For the logistics robots, We also need to face the different scenarios.\\
 \indent
 In addition to safety, passengers’ ride experience is also important. The measurement of ride experience includes, but is not limited to, scenario coverage, traffic regulation and comfort. For scenario coverage, the motion planner should not only be able to handle simple driving scenarios (e.g., stop, nudge, yield and overtake) but also handle multilane driving, heavy traffic and other complicated on-road driving scenarios.
 Planning within traffic regulations is also important for ride experience. In addition to being a safety requirement, following the traffic regulations will also minimize the risk of accidents and reduce emergency reactions for autonomous driving. The comfort during autonomous driving is also important. In motion planning, comfort is generally measured by the smoothness of the provided autonomous driving trajectory.\\
 \indent
 This report is organized as follows: Chapter 1 is delicated to search-based algorithm. Chapter 2 is delicated to EM planner.
 
 
 \chapter{Seach-based Algorithm}
 For level-4 on-road autonomous driving motion planning, a lane-change strategy is necessary. One common approach is to develop a search algorithm with a cost functional on all possible lanes and then
 select a final trajectory from all the candidates with the lowest cost(See Figure 1.1).
 \begin{figure}[ht]
 	\centering
 	\includegraphics[width=0.6\linewidth]{1_.png}
 	\caption{Ilustration of demonstrated driving scenario consisting of multilane driving in presence of traffic lights. [1]}
 	\label{fig:1.1} 
 \end{figure}
 \section{Problem of Statement}
 In this section, we define the addressed problem. First, a general driving problem is defined, followed by the formulation of search space and obstacles. Finally, we provide the details about the vehicle model and the cost evaluation.
 \subsection{Driving In Dynamic Environment}
 Driving is a complex task consisting of continuous planning and execution in order to achieve desired goals and avoid collisions with other participants, obey traffic rules, comply with vehicle dynamics and factors like comfort, safety and efficiency. To fully automate driving, the vehicle has to be able to autonomously make decisions and plan its motion, while considering all mentioned requirements. The environment is usually highly dynamic, with speeds that may reach 50m/s or above. Moreover, the environment is complex, including many different participants, traffic rules,traffic control devices, etc. The mentioned conditions impose many different constraints on the driving trajectory.\\
 \indent
 The mayor challenges can be stated as: i) vehicle dynamics influence feasibility of the plans, ii) dynamic constraints are not known during initial planning, iii) the real motion of other participants deviates from the predicted one, iv) planning for long horizons with dynamic constraints is computationally expensive, v) long horizon planning is necessary to achieve long-term benefits such as energy efficiency, vi) conservative assumptions narrow down the search space, which can cause the loss of solution even in the case it exists. Therefore, a frequent replanning with long horizons is necessary while considering the vehicle model and environment as well.
 \subsection{Search Space}
 To tackle dynamic obstacles and avoid the risk of losing quality solutions, we use the 3D space-time $\Omega$ as a search space via Cartesian product of 2D configuration space and time dimension:\\
 \begin{equation}\label{def:ratio}
 \Omega = \{q \equiv [t,s,l]^T 、\, |\, t\in \mathcal{R}^+, s\in \mathcal{R}^+ ,l \in[1,N_l]\}
 \end{equation}\\
 \indent
 Here, t is time, s is the longitudinal position along the road and l is the lateral position on a road. Dimension l is defined such that the middle of the rightmost lane has value 1 while the middle of the left-most lane has value $N_l$. The value 1.5 means that vehicle is halfway between lane 1 and 2.
 \subsection{Obstacles}
 We consider several types of constraints/obstacles, such as constraints imposed by other vehicles, traffic lights, speed limits and forbidden lane-change.\\
 \indent
 1)Vehicle obstacle: Other vehicles on the road represent obstacles for ego vehicle and constrain it’s motion. The violation of these constraints can be manifested not only as a direct collision, but sometimes also as a violation of the driving rules, such as overtaking from right side or slow overtaking from the left side. For a certain vehicle $\mathcal V_k$, the trajectory of its center is described with $s_k(t)$ and $l_k(t)$, while suitable lower and upper bounds can be defined as:
 \begin{equation}
 L_s = L_k / 2 + L_{ego} / 2 
 \end{equation}
 \begin{equation}
 \underline{s}_k(t) = s_k(t) - L_s
 \end{equation}
  \begin{equation}
 \overline{s}_k(t) = s_k(t) + L_s
 \end{equation}
 where $L_k$ is the length of vehicle $\mathcal V_k$ and $L_{ego}$ is the length of ego vehicle. Thus, the$L_{ego}$ is practically incorporated within the obstacle so ego vehicle can be considered as a point. Based on this, the corresponding obstacle can be defined as:
 \begin{equation}
 	\mathcal O_k^V = \{q \in \Omega \, | \, s(t) \in [\underline{s}_k(t),\overline{s}_k(t)]\}
 \end{equation}
 A collision check for a given q, or the condition for which collision occurs can be validated by:
 \begin{equation}
 	\tau (\exists q\in \mathcal O_k^V \, | \,l(t) \in (l_k(t)-1, l_k(t)+1) )
 \end{equation}
 Where $\tau(S)$ denotes the logical value (1 or 0) of the statement S. The assumption made here is that each vehicle
 occupies the whole lane, so if ego vehicle center deviates from the middle of the lane, it is colliding with vehicle in the adjacent lane. It is important to note that this is different from driving in a lane when executing the plan, as the control is not ideal and the vehicle can deviate from the middle of the lane. Figure 1.2 shows an example of geometric representation of the vehicle obstacle within a defined search space $\Omega$. The presented vehicle speeds up and then slows down.
  \begin{figure}[ht]
 	\centering
 	\includegraphics[width=0.6\linewidth]{1_2.png}
 	\caption{Obstacle created by vehicle which is speeding up and slowing down.
 	 [1]}
 	\label{fig:1.2} 
 \end{figure}\\
\indent
Beside collision, it is sometimes forbidden to overtake the vehicle from the right side. This can be expressed by a collision-test given in (1.7). This is modeled by prohibiting velocities greater than the velocity of a vehicle on the left. Beside using the velocity limit, position is used so that in the case when a vehicle tries to overtake the ego vehicle, and ceases overtaking for some reason, the ego vehicle does not slow down too. The corresponding collision test is formulated via:
\begin{equation}
 \tau (\exists q\in \mathcal O_k^V \, | \,l(t) \in [1, l_k(t)-1],\frac{\partial s(t)}{t} \geq 个\frac{\partial s_k(t)}{t},s_k(t) \geq s(t) )
\end{equation}
Practically, overtaking a vehicle requires only a velocity greater than the velocity of a vehicle. However, to limit the time of the overtaking maneuver, in several countries (e.g. Austria) there is also a limit on the minimum velocity difference $\Delta v_{ov} $, when overtaking other vehicles. The corresponding collision test can be formulated as:
\begin{equation}
 \tau (\exists q\in \mathcal O_k^V \, | \,l(t) \in [l_k(t)+1, N_l],\frac{\partial s(t)}{t} \leq \frac{\partial s_k(t)}{t} + \Delta v_{ov} )	
\end{equation}
In multilane urban driving scenarios, rules for overtaking are not applicable.\\
\indent
2)Traffic light obstacle: The traffic light is a traffic control device which prohibits passing the defined line, during specific periods in time on certain lane. Figure 1.3 shows obstacles created by two traffic lights across all lanes although they can be active on a single or several lanes. The obstacle is defined as:
\begin{equation}
\mathcal{O}_{ki}^{TL} = \{ q \in \Omega \. | \, s = s_k,l=l_k, t \in [t_{ki}, t_{ki} + \Delta t_{ki}]\}
\end{equation}
  \begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\linewidth]{1_3.png}
	\caption{Obstacles created by two traffic lights.
		[1]}
	\label{fig:1.3} 
\end{figure}
Each traffic light represents infinitely many obstacles, periodic in t, with the constant or variable period depending
on the traffic light control system. The collision check is performed by evaluating:
\begin{equation}
	\tau(q \cap \mathcal{O}_{ki}^{TL} \neq \emptyset)
\end{equation}
The vehicle trajectory should not pass trough the region of the traffic light at the time when the red light is on.\\
\indent
3)Speed limit: Speed limits may originate from speed limit signs, road curvature or some other factors. They are defined on certain segment of the road and active in the following region of $\Omega$:
\begin{equation}
\mathcal{O}_{k}^{TL} = \{ q \in \Omega\,|\,
s \in [s_k, s_k + \Delta s_k]\}
\end{equation}
The collision check is validated by:
\begin{equation}
\tau(\exists q \in \mathcal{O}_{k}^{TL} \,|\, \frac{\partial s(t)}{t} \geq v_{k_{MAX}} )
\end{equation}
On this segment, the vehicle velocity, represented by a gradient in direction of t, must not exceed the defined value.\\
\indent
4)Forbidden lane-change, solid line: Lane-change prohibition can be also defined on certain segments of the road. It is usually marked with the solid lane line. The obstacle representation is given as:
\begin{equation}
\mathcal{O}_{ki}^{LC} = \{ q \in \Omega \,|\,s \in [s_k, s_k + \Delta s_k],l(t) \in (l_i, l_i+1) \}
\end{equation}
Prohibition may be applicable to both directions, where the collision check is performed by:
\begin{equation}
\tau(q \cap \mathcal{O}_{ki}^{LC} \neq \emptyset)
\end{equation}
Alternatively, the prohibition can hold for single direction. Left-wise lane change prohibition is defined via collision
test (1.15), while the right-wise is defined via negative partial
derivative.
\begin{equation}
\tau(\exists q \in \mathcal{O}_{ki}^{LC} \,|\, \frac{l(t)}{t} > 0)
\end{equation}
Obstacles formulated above are the most common constraints in everyday driving, and the majority of situations can be described by the combination of these. Clearly, multiple obstacles can be active at the same time. It is worth pointing out that the collision checking with respect to such defined obstacles appears to be rather trivial, since it usually reduces to closed-form analysis whether some elementary, analytically defined curves intersect or not, or if the gradient of these curves attain certain values.

 \subsection{Vehicle Model}
 To model the vehicle motion for planning purposes, longitudinal and lateral dynamics should be derived. Assuming
 that the vehicle orientation does not deviate much from the road direction, the longitudinal motion is given by:
 \begin{equation}
 v(t) = \frac{\partial s(t)}{t}
 \end{equation}
 \begin{equation}
  a(t) = \frac{\partial v(t)}{t} = \frac{F_m(t) - F_r(t)}{m}
 \end{equation}
 where v(t) and a(t) are velocity and acceleration along s, and $F_m(t) \,and\, F_r (t) $are forces generated by the motor and resistive force respectively. The rest of the vehicle model is presented in [2] where resistive forces and powertrain losses are modeled in detail. The vehicle model is used for computing the cost of a transition between certain states,$costtrans(v_i , v_f , t_t )$.\\
 \indent
 Since planning includes lane changes as well, modeling the lateral motion is of particular importance. This is not straightforward because of the vehicle kinematics and dynamics. For planning purposes, it is important that the model is conservative so that resulting trajectory is feasible, yet not too conservative to disregard many feasible trajectories. Therefore, the lateral motion is modeled as linear in time such that the vehicle needs a specific time $T _{LC}$ to execute the full lane change. This simplification limits the use of a lane change on smaller velocities, which is acceptable as it can be considered a parking maneuver. Alternatively, the clearance for the lane change on smaller velocities can be provided with by increasing safety buffer around the obstacles.
 \subsection{Cost Function}
 A cost function is used to evaluate quality of a given trajectory. It can reflect multiple goals such as: short travel time [3], comfort [4], safety [5], energy efficiency [2], traffic rules (driving on the rightmost lane [6]) or a combination of these [7]. The design of the cost function is particularly important as it influences vehicle behavior and defines the optimal solution. Cost function used in this work is reflecting energy efficiency and is explained in details in [2], [8] with the additional constant cost for each lane change. The cost function is kept simple while other desired behaviors are implicitly defined through the obstacle formulation.
 \section{Optimal Motion Planning Framework}
 In this section, we elaborate on the proposed optimal MP framework. First, some general aspects of the framework are described, followed by the clarification of individual features.
 \subsection{Framework}
 The proposed framework is based on A* search method [9], guided by an exact cost-to-go map from a relaxed problem in an MPC-like replanning scheme. Each $T_rep$ seconds, replanning is triggered with the current measurement of positions and velocities of other vehicles, traffic lights timing data together with the map data. Based on measurements, the motion of other vehicles is predicted and collision-free trajectory for a defined horizon is generated.\\
 \indent
 The trajectory is generated by a grid-like searching using A*. The grid is constructed by the discretization of t, s and l from the original continuous search space definition. Velocity $v$ is additionally used to provide completeness because of the longitudinal dynamics of the model. Starting from the initial configuration, defined as the initial node, chosen as the first current node, all neighbors are determined by expanding the current node. The resulting child nodes are added to the OPEN list. If the child node is already in the OPEN list, and new child node has a lower cost, the parent of that node is updated, otherwise it is ignored. From the OPEN list, the
 node with the lowest cost is chosen to be the next current node and the procedure is repeated until horizon is reached, the whole graph is explored or the computation time limit for planning is reached. Finally, the node closest to the horizons is used to reconstruct the trajectory. The pseudocode for this procedure is presented in Figure 1.4.
   \begin{figure}[ht]
 	\centering
 	\includegraphics[width=0.6\linewidth]{1_4.png}
 	\caption{Pseudocode using A* for horizon
 		[2]}
 	\label{fig:1.4} 
 \end{figure}\\
\indent
To avoid rounding errors, as the expansion of node creates multiple transitions which in general do not end at gridpoints, the hybrid A* approach [10] is used for planning. Hybrid A* also uses the grid, but keeps continuous values for the next expansion without rounding it to the grid, thus preventing the accumulation of rounding errors.\\
\indent
As $v$ belongs to the discrete set of values as defined in the expansion (Figure 1.5), the hybrid A* approach is used only for $t, s, l$. Therefore, each node n contains 14 values: four indices for $v, t, s, l, (n.v_k , n.t_k , n.s_k , n.l_k )$, four indices for the parent node (to reconstruct trajectory), three remainders from the discretization of $t, s$ and$ l (n.t_r , n.s_r , n.l_r )$, the direction of the lane-change $n.l_dir$ , the exact
cost-to-come to the node ($n.g$), and the estimated total cost of traveling from the initial node to the goal region ($n.f$ ). The value $n.f$ is computed as $n.g + h(n)$, where $h(n)$ is the heuristic function.
   \begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\linewidth]{1_5.png}
	\caption{Pseudocode using A* for expand function
		[2]}
	\label{fig:1.5} 
\end{figure}\\
\indent
The planning clearly requires processing time. The compensation of the planning time can be achieved by introducing $T_{plan}$ , a guaranteed upper bound on planning time. The planning is then initiated from a position where the vehicle would be after the $T_{plan}$ . The old trajectory is executed while the new one is being processed. Thus, the new trajectory is already planed when $T_{plan}$ arrives.

\subsection{Node Expansion}
To build trajectories iteratively, nodes are expanded and child nodes are generated, progressing toward the goal. From each node $n$, only dynamically feasible and collision-free child nodes $n'$should be generated. A single child node is generated for each possible longitudinal and lateral motion variant.\\
\indent
The longitudinal motion variants are generated by assuming uniform accelerations from the inherited parent velocity, so that the discrete final velocities (represented by the array $v_f$) are reached at expansion limits. Expansion limits are defined by $ \Delta s_{exp}$ for distance and $\Delta t_{exp} $for time (Figure 1.6). Since trajectories reflect the motion with the uniform acceleration, the average velocity of a specific motion variant equals $v = (v_i + v_f ) /2$. If $v < \Delta s_{exp} /\Delta t_{exp}$ , the trajectory will end on time expansion limit $\Delta t = \Delta t_{exp}$. Otherwise,
it will end on the distance expansion limit $\Delta s = \Delta s_{exp}$. Distance and time values ($\Delta s$ and $\Delta t$) for each variant are summed with the parent node’s remainders $n.s_r$ and $n.t_r$. Resulting sums are used to generate child nodes by increasing parent node’s indices ($n.s_k$ and $n.t_k$ ) with the quotient of division of sums with discretization steps of the grid ($\Delta s$ grid and $\Delta t$ grid ), and computing new remainders. For each child node from the array $n'$, costs are computed as well. Cost-to-come is inherited from the parent and increased by the cost of transition. Cost-to-go is provided by the heuristic function explained in the following subsection. The compliance with the vehicle’s internal constraints (e.g.maximum acceleration) is checked and the nodes that violate these constraints are removed.
   \begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\linewidth]{1_6.png}
	\caption{Expanding parent node $n$ to different child nodes $n'$ by piecewise constant acceleration.[2]}
	\label{fig:1.6} 
\end{figure}\\
\indent
Generated longitudinal motion variants are then used for lateral motion expansion. If the parent node is in the middle of the lane ( $l$ is the integer), variants for possible lane change right and left, beside staying in the lane are generated. Generated variants are tripled, one set of longitudinal variants for each. The values $n'.l_k$ and $n'.l_r$ are increased or decreased for the lane changes left or right respectively. They are modified by the value $\Delta t/T_{LC}$ based on the travel time of the particular variant, and the defined lane change time $T_{LC}$ . If the parent node is already in the process of lane change, lane change is progressed without generating other lateral motion variants. Finally, compliance with obstacles such as other vehicles, traffic lights, etc. is checked and all child nodes and motion variants that are not collision-free are removed.

\subsection{Heuristic Function}
The heuristic function $h(n)$ is used to estimate the cost needed to travel from some node $n$ to the goal state (cost-to-go). As it is shown in [9], if the heuristic function is underestimating the exact cost to go, A* search provides the optimal trajectory. For the shortest path search, the usual heuristic function is the Euclidian distance. To find the energy optimal velocity trajectory, the heuristic function must underestimate the energy needed to drive to the goal. In this framework, the cost-to-go map resulting from the backward search for the relaxed problem is used as heuristic function. The cost-to-go computation phase is executed only once at the beginning of the trip, or if the goal is changed. The computation is performed by using backward dynamic programming (DP), starting from the goal state ($s$ and $v$), backward in $s$, as it was shown in [2].\\
\indent
In this phase, only time invariant constraints are considered (e.g. speed limits) with topological road profile and the vehicle model without considering time-varying constraints. The resulting cost-to-go map is an admissible heuristic, as other vehicles can prohibit certain regions of the state space, which may only increase the cost to travel from the initial state to the goal region. This is valid if platooning effects are neglected, as platooning can potentially reduce the airdrag effect (which is considered in the initial computation), and decrease the cost of travel, but for compact vehicles, this effect is usually negligible. Heuristic function $h(s,v)$ depends only on $s$ and $v$. The resulting heuristic function is applied based on child node’s $s$ and $v$ values, while neglecting $t$ and $l$ values.

\subsection{Search Horizons}
The planing is performed until any of the trajectories reaches time ($T_{hor}$ ) or distance ($S_{hor}$ ) search horizon. Slower driving trajectories will reach the time, while faster trajectories will reach the distance horizon. Thus, the unnecessary planning can be avoided. If only one is chosen (e.g., $T_{hor}$ ) other one could adopt a large even infinite value. The search horizons should not be confused with local expansion limits, which uses a similar principle, but represents atomic motion segments when building the whole trajectory.

\subsection{Vehicle Motion Prediction}
Though it is required for prediction of potential collisions, the perfect knowledge of the future motion of other vehicles is not available in principle. A naive way to predict the motion is to assume that the vehicles will continue to drive with their current velocity and stay in the current lane. On the other hand, a motion planning framework should provide collision-free plans even if trajectories deviate from the predicted one and the environment perception system introduces estimation errors. Therefore, safety buffers are used to increase obstacle regions, and frequent replanning is executed. The approach introduced in this framework is that the most intuitive prediction of driving (constant velocity) is used for finding the optimal trajectory, but an additional safety mechanism ensures a collision-free plan even for the worst case error regarding the relative distance estimation. This is provided by adding a step-like safety buffer to the obstacle. The lower and upper bound of the vehicle obstacle can be defined as:
\begin{equation}
\hat{\underline{s}}_k(t) = \hat{s}_k(t_0) + \hat{v}_k(t_0)(t-t_0) - L_s -s_b(t)
\end{equation}
\begin{equation}
\hat{\overline{s}}_k(t) = \hat{s}_k(t_0) + \hat{v}_k(t_0)(t-t_0) + L_s + s_b(t)
\end{equation}
\begin{equation}
\begin{cases}
\Delta s_{max}, \qquad t_0 \leq t \leq t_0 + T_{rep}\\
3  \Delta s_{max}, \qquad t_0 + T_{rep} \leq t \leq t_0 + T_{hor}
\end{cases}
\end{equation}
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\linewidth]{1_7.png}
	\caption{Predicting movement of other vehicle - linearization.[1]}
	\label{fig:1.7} 
\end{figure}
where $\Delta s_{max}$ is the maximum error of the vehicle relative distance estimation. The safety buffer $s_b$ is increased after $T_{rep}$ (the next replanning instance) to maintain robustness,
so that in the next replanning instance, the vehicle always starts from the position that is collision-free according to a
new safety buffer. This is visualized in the Figure 1.7, showing the worst case scenario. The estimation error is such that
in the first planning instance, $\Delta s_{max}$ is positive, while in the second instance, it is negative. It can be seen that the safety buffer from the first planning instance ensures that the trajectory is outside of obstacle area for the time interval $[t_0 , t_0 + T_{rep} ]$ and the trajectory is outside of the safety buffer from the second planning instance for the time interval
$[t_0 + T_{rep} , t_0 + 2·T_{rep} ]$. This safety buffer provides a partial
robustness for deviations from the predicted trajectory as well, but no guarantees can be provided.



 
 \chapter{EM Motion Planner}
 This manuscript presents the Apollo EM planner, which is based on an EM-type iterative algorithm([11]). This planner targets safety and ride experience with a multilane, path-speed iterative, traffic rule and decision combined design.
 \section{Multilane Strategy}
 In the chapter1, we talk about one common approach is to develop a search algorithm
 with a cost functional on all possible lanes, This approach has some difficulties. First, the search space is expanded across multiple lanes, which causes the algorithm to be computationally expensive. Second, traffic regulations (e.g., right of the road, traffic lights) are different across lanes, and it is not easy to apply traffic regulations under the same frame. Furthermore, trajectory stability that avoids sudden changes between cycles should be taken into consideration. It is important to follow consistent on-road driving behavior to inform other drivers of the intention of the autonomous driving vehicle.\\
 \indent
 Typically, a multilane strategy should cover both nonpassive and passive lane-change scenarios. In EM planner, a nonpassive lane-change is a request triggered by the routing module for the purpose of reaching the final destination. A passive lane change is defined as an ego car maneuver when the default lane is blocked by the dynamic environment. In both passive and nonpassive lane changes, we aim to deliver a safe and smooth lane change strategy with a high success rate.
 Thus, we propose a parallel framework to handle both passive and nonpassive lane changes. For candidate lanes, all obstacles and environment information are projected on lane-based Frenet frames. Then, the traffic regulations are bound with the given lane level strategy. Under this framework, each candidate lane will generate a best-possible trajectory based on the lane-level optimizer. Finally, a crosslane trajectory decider will determine which lane to choose based on both the cost functional and safety rules.
 \subsection{The Architecture of EM planner}
 Figure 2.1 presents an overview of EM planner. On top of the planner, all sources of information are collected and synced at the data center module. After data collection, the reference line generator will produce some candidate lane-level reference lines along with information about traffic regulations and obstacles. This process is based on the high-definition map and navigation information from the routing module. During lane-level motion planning, we first construct a Frenet frame based on a specified reference line. The relation between the ego car and its surrounding environment is evaluated in the Frenet frame constructed by the reference line, as well as traffic regulations. Furthermore, restructured information passes to the lane-level optimizer.
    \begin{figure}[ht]
 	\centering
 	\includegraphics[width=0.6\linewidth]{2_1.png}
 	\caption{EM Framework.[12]}
 	\label{fig:2.1} 
 \end{figure}

\subsection{The Lane-Level Optimizer}
The lane-level optimizer module performs path optimization and speed optimization. During path optimization, information about the surroundings is projected on the Frenet frame(E-step).Based on the information projected in the Frenet frame, a smooth path is generated (M-step). Similarly, during speed optimization, once a smooth path is generated by the path optimizer, obstacles are projected on the station-time graph (E-step). Then, the speed optimizer will generate a smooth speed profile (M-step). Combining path and speed profiles, we will obtain a smooth trajectory for the specified lane. In the last step, all lane-level best trajectories are sent to the reference line trajectory decider. Based on the current car status, regulations and the cost of each trajectory, the trajectory decider will decide a best trajectory for the ego car maneuver.
 
 
\section{EM Planner at Lane Level}
In this section, we discuss the lane-level optimization problem. Figure 2.1 shows the path-speed EM iteration inside lane-level planning. The iteration includes two E-steps and two M-steps in one planning cycle. The trajectory information will iterate between planning cycles. We explain the submodules as follows.
    \begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\linewidth]{2_2.png}
	\caption{EM Iteration.[12]}
	\label{fig:2.2} 
\end{figure}\\
\indent
In the first E-step, obstacles are projected on the lane Frenet frame. This projection includes both static obstacle projection and dynamic obstacle projection. Static obstacles will be projected directly based on a Cartesian-Frenet frame transformation. In the Apollo framework, the intentions of dynamic obstacles are described with an obstacle moving trajectory. Considering the previous cycle planning trajectory, we can evaluate the estimated dynamic obstacle and ego car positions at each time point. Then, the overlap of dynamic obstacles and the ego car at each time point will be mapped in the Frenet frame. In addition, the appearance of dynamic obstacles during path optimization will eventually lead to nudging. Thus, for safety considerations, the SL projection of dynamic obstacles will only consider low-speed traffic and oncoming obstacles. For high-speed traffic, EM planner’s parallel lane-change strategy will cover the scenario. In the second E-step, all obstacles, including high-speed, low-speed and oncoming obstacles, are evaluated on the station-time frame based on the generated path profile. If the obstacle trajectory has overlap with the planned path, then a corresponding region in the station-time frame will be generated.\\
\indent
In two M-steps, path and speed profiles are generated by a combination of dynamic programming and quadratic programming. Although we projected obstacles on SL and ST frames, the optimal path and speed solution still lies in a non-convex space. Thus, we use dynamic programming to first obtain a rough solution; meanwhile, this solution can provide obstacle decisions such as nudge, yield and overtake. We use the rough decision to determine a convex hull for the quadratic-programming-based spline optimizer. Then, the optimizer can find solutions within the convex hull. We will cover the modules in the following.

\subsection{SL and ST Mapping}
The SL projection is based on contin-
uous curvature derivative smooth reference line. In Cartesian space, obstacles and the
ego car status are described with location and heading $(x, y, θ)$, as well as curvature and the derivative of curvature $(\kappa, d_{\kappa})$ for the ego car. Then, these are mapped to the Frenet frame coordinates $(s, l, dl, ddl, dddl)$, which represent station, lateral, and lateral derivatives. Since the positions of static obstacles are time invariant, the mapping is straight forward. For dynamic obstacles, we mapped the obstacles with the help of the last cycle trajectory of the ego car. The last cycle’s moving trajectory is projected on the Frenet frame to extract the station direction speed profile. This will provide an estimate of the ego car’s station coordinates given a specific time. The estimated ego car station coordinates will help to evaluate the dynamic obstacle interactions.\\
\indent
Once an ego car’s station coordinates have interacted with an obstacle trajectory point with the same time, a shaded area on the SL map will be marked as the estimated interaction with the dynamic obstacle. Here, the interaction is defined as the ego car and obstacle bounding box overlapping. For example, as shown in Figure 2.3, 
  \begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\linewidth]{2_3.png}
	\caption{SL projection with oncoming traffic example.[12]}
	\label{fig:2.3} 
\end{figure}
an oncoming dynamic obstacle and corresponding trajectory estimated from the prediction module are marked in red. The ego car is marked in blue. The trajectory of the oncoming dynamic obstacle is first discretized into several trajectory points with time, and then the points are projected to the Frenet frame. Once we find that the ego car’s station coordinates have an interaction with the projected obstacle points, the overlap region (shown in purple in the figure 2.3) will be marked in the Frenet frame.\\
\indent
ST projection helps us evaluate the ego car’s speed profile. After the path optimizer generates a smooth path profile in the Frenet Frame, both static obstacle and dynamic obstacle trajectories are projected on the path if there are any interactions.An interaction is also defined as the bounding boxes overlapping. In Figure 2.4,
  \begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\linewidth]{2_4.png}
	\caption{ST projection with cut-in obstacle and obstacle behind ego care.[12]}
	\label{fig:2.4} 
\end{figure}
 one obstacle cut into the ego driving path at 2 seconds and 40 meters ahead, as marked in red, and one obstacle behind the ego car is marked in green. The remaining region is the speed profile feasible region. The speed optimization M-step will attempt to find a feasible smooth solution in this region.
 
 \subsection{M-Step DP Path}
 The M-step path optimizer optimizes the path profile in the Frenet frame. This is represented as finding an optimal function of lateral coordinate $l = f(s)$ w.r.t. station coordinate in nonconvex SL space (e.g., nudging from left and right might be two local optima). Thus, the path optimizer includes two steps: dynamic-programming-based path decision and spline-based path planning. The dynamic
 programming path step provides a rough path profile with feasible tunnels and obstacle nudge decisions. As shown in Figure 2.5, the step includes a lattice sampler, cost function and dynamic programming search.
   \begin{figure}[ht]
 	\centering
 	\includegraphics[width=0.6\linewidth]{2_55.png}
 	\caption{Dynamic programming structure. [12]}
 	\label{fig:2.5} 
 \end{figure} \\
\indent
The lattice sampler is based on a Frenet frame. As shown in Figure 2.6, multiple rows of points are first sampled ahead of the ego vehicle. Points between different rows are smoothly connected by quintic polynomial edges. The interval distance between rows of points depends on the speed, road structure, lane change and so forth. The framework allows customizing the sampling strategy based on application scenarios. For example, a lane change might need a longer sampling interval than current lane driving. In addition, the lattice total station distance will cover at least 8 seconds or 200 meters for safety considerations.
   \begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\linewidth]{2_6.png}
	\caption{Dynamic programming path optimizer sampling for default lane and change lane. [12]}
	\label{fig:2.6} 
\end{figure} \\
\indent
After the lattice is constructed, each graph edge is evaluated by the summation of cost functionals. We use information from the SL projection, traffic regulations and vehicle dynamics to construct the functional. The total edge cost functional is a linear combination of smoothness, obstacle avoidance and lane cost functionals.
\begin{equation}
C_{total}(f(s)) = C_{smooth}(f) + C_{obs}(f)+ C_{guidence}(f)
\end{equation}\\
\indent
The smoothness functional for a given path is measured by:
\begin{equation}
C_{smooth}(f) = w_1 \int (f'(s))^2 ds + w_2 \int (f^{''}(s))^2 ds + w_3 \int (f^{'''}(s))^2 ds
\end{equation}
In the smoothness cost functional, $f'(s)$ represents the heading difference between the lane and ego car, $f^{''}(s)$ is related to the curvature of the path, and $f^{'''}(s)$ is related to the derivative of the curvature of the ego car. With the form of polynomials, the above cost can also be evaluated analytically. \\
\indent
The obstacle cost given an edge is evalu-
ated at a sequence of fixed station coordinates $\{s_0 , s_1 , ..., s_n \}$ with all obstacles. The obstacle cost functional is based on the bounding box distance between the obstacle and ego car. Denote the distance as $d$. The form of individual cost is given
by:
\begin{equation}
C_{obs}(d) = 
\begin{cases}
0, & d > d_n\\
C_{nudge}(d - d_c), & d_c < d < d_n\\
C_{collision}, & d< d_c
\end{cases}
\end{equation}
where $C_{nudge}$ is defined as a monotonically decreasing function. $d_c$ is set to leave a buffer for safety considerations. The nudge range d n is negotiable based on the scenario. $C_{collision}$ is the collision cost, which has a large value that helps to detect infeasible paths.\\
\indent
The lane cost includes two parts: guidance line cost and on-road cost. The guidance line is defined as an ideal driving path when there are no surrounding obstacles. This line is generally extracted as the centerline of the path. Define the guidance line function as $g(s)$. Then, it is measured as:
\begin{equation}
C_{guidence}(f) = \int (f(s)-g(s))^2 ds
\end{equation}\\
\indent
The on-road cost is typically determined by the road boundary. Path points that are outside the road will have a high penalty.\\
\indent
The final path cost is a combination of all these smooth, obstacle and lane costs. Then, edge costs are used to select a candidate path with the lowest cost through a dynamic programming search. The candidate path will also determine the obstacle decisions. For example, in Figure 2.6, the obstacle is marked as a nudge from the right side.

\subsection{M-Step Spline QP Path}
The spline QP path step is a refinement of the dynamic programming path step. In a dynamic programming path, a feasible tunnel is generated based on the selected path. Then, the spline-based QP step will generate a smooth path within this feasible tunnel, as shown in Figure 2.7.
   \begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\linewidth]{2_7.png}
	\caption{Spline QP Path Example. [12]}
	\label{fig:2.7} 
\end{figure}\\
\indent
The spline QP path is generated by optimizing an objective function with a linearized constraint through the QP spline solver. Figure 2.8 shows the pipeline of the QP path step.
   \begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\linewidth]{2_8.png}
	\caption{Spline QP Path Example. [12]}
	\label{fig:2.8} 
\end{figure}\\
\indent
The objective function of the QP path is a linear combination of smoothness costs and guidance line cost. The guidance line in this step is the DP path. The guidance line provides an estimate of the obstacle nudging distance. Mathematically, the QP path step optimizes the following functional:
\begin{equation}
C_{s}(f) = w_1 \int (f'(s))^2 ds + w_2 \int (f^{''}(s))^2 ds + w_3 \int (f^{'''}(s))^2 ds + w_4 \int (f(s) - g(s))^2 ds
\end{equation}
where $g(s)$ is the DP path result. $f'(s)$, $f^{''}(s)$ and $f^{'''}(s)$ are related to the heading, curvature and derivative of curvature. The objective function describes the balance between nudging obstacles and smoothness.\\
\indent
The constraints in the QP path include boundary constraints and dynamic feasibility. These constraints are applied on $f(s)$, $f'(s)$ and $f^{''}(s)$ at a sequence of station coordinates $s_0$ , $s_1$ , ...., $s_n$. To extract boundary constraints, the feasible ranges at station points are extracted. The feasible range at each point is described as $(l_{low,i} \leq l_{high,i} )$. In EM planner, the ego vehicle is considered under the bicycle model. Thus, simply providing a range for $l = f(s)$ is not sufficient since the heading of the ego car also matters.
  \begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\linewidth]{2_9.png}
	\caption{Spline QP Path Constraint Linearization. [12]}
	\label{fig:2.9} 
\end{figure}\\
\indent
As shown in Figure 2.9, to keep the boundary constraint convex and linear, we add two half circles on the front and rear ends of the ego car. Denote the front-to-rear wheel center distance as $l_f$ and the vehicle width as $w$. Then, the lateral position of the left-front corner is given by
\begin{equation}
	l_{left \, front \, corner} = f(s) + \sin \theta l_f +w/2
\end{equation}
where $\theta$ is the heading difference between the ego car and road station direction. The constraint can be further linearized using the following inequality
approximation:
\begin{equation}
 f(s) + \sin \theta l_f +w/2 \leq f(s)+ f'(s)l_r+w/2
\end{equation}
Similarly, the linearization can be applied on the remaining three corners. The linearized constraints are good enough since θ is generally small. For
$\theta < \pi/12$, the estimation will be less than 2 - 3cm conservative on the lateral direction compared to the constraint without linearization.\\
\indent
The range constraints of $f^{''}(s)$ and $f_{'''}(s)$ can also be used as dynamic feasibility since they are related to curvature and the curvature derivative. In addition to the boundary constraint, the generated path shall match the ego car’s initial lateral position and derivatives $(f(s_0), f'(s_0), f^{''}(s_0))$. Since all constraints are linear with respect to spline parameters, a quadratic programming solver can be used to solve the problem very fast.

\subsection{M-Step DP Speed Optimizer}
The speed optimizer generates a speed profile in the ST graph, which is represented as a station function with respect to time $S(t)$. Similar to in the path optimizer, finding a best speed profile on the ST graph is a non-convex optimization problem. We use dynamic programming combined with spline
quadratic programming to find a smooth speed
profile on the ST graph. In Figure 2.10, the DP speed step includes a cost functional, ST graph grids and dynamic programming search. The generated result includes a piecewise linear speed profile, a feasible tunnel and obstacle speed decisions, as shown in Figure 2.11. The speed profile will be used in the spline QP speed step as a guidance line, and the feasible tunnel will be used to generate a convex region.
  \begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\linewidth]{2_10.png}
	\caption{DP Speed Optimizer. [12]}
	\label{fig:2.10} 
\end{figure}
  \begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\linewidth]{2_11.png}
	\caption{DP Speed Optimizer. [12]}
	\label{fig:2.11} 
\end{figure}\\
\indent
In detail, obstacle information is first discretized into grids on the ST graph. Denote $(t_0 , t_1 , ..., t_n)$ as equally spaced evaluated points on the time axis with interval $dt$. A piecewise linear speed profile function is represented as $S = (s_0, s_1 , ..., s_n )$ on the grids. Furthermore, the derivatives are approximated by the finite difference method.\\
\indent
The goal is to optimize a cost functional in the ST graph within the constraints. In detail, the cost for the DP speed optimizer is represented as follows:
\begin{equation}
C_{total}(S) = w_1 \int_{t_0}^{t_n} g(S' - V_{ref})dt + w_2 \int_{t_0}^{t_n}(S^{''})^2dt + w_3 \int_{t_0}^{t_n} (S^{'''})^2dt + w_4 C_{obs}(S)
\end{equation}
The first term is the velocity keeping cost. This term indicates that the vehicle shall follow the designated speed when there are no obstacles or traffic light restrictions present. $V_{ref}$ describes the reference speed, which is determined by the road speed limits, curvature and other traffic regulations. The $g$ function is designed to have different penalties for values that are less or greater than $V_{ref}$. The acceleration and jerk square integral describes the smoothness of the speed profile. The last term, $C_{obs}$ , describes the total obstacle cost. The distances of the ego car to all obstacles are evaluated to determine the total obstacle costs.\\
\indent
The dynamic programming search space is also
within the vehicle dynamic constraints. The dynamic constraints include acceleration, jerk limits and a monotonicity constraint since we require that the generated trajectories do not perform backing maneuvers when driving on the road. Backing can only be performed under parking or other specified scenarios. The search algorithm is straightforward; some necessary pruning based on vehicle dynamic constraints is also applied to accelerate the process. We will not discuss the search part in detail.

\subsection{M-Step QP Speed Optimizer}
Since the piecewise linear speed profile cannot satisfy dynamic requirements, the spline QP step is needed to fill this gap. In Figure 2.12, the spline QP speed step includes three parts: cost functional, linearized constraint and spline QP solver.
 \begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\linewidth]{2_12.png}
	\caption{Spline QP speed optimizer. [12]}
	\label{fig:2.12} 
\end{figure}\\
\indent
The cost functional is described as follows:
\begin{equation}
C_{total}(S) = w_1 \int_{t_0}^{t_n} (S - S_{ref})^2dt + w_2 \int_{t_0}^{t_n}(S^{''})^2dt + w_3 \int_{t_0}^{t_n} (S^{'''})^2dt 
\end{equation}
The first term measures the distance between the DP speed guidance profile $S_{ref}$ and generated path S. The acceleration and jerk terms are measures of the speed profile smoothness. Thus, the objective function is a balance between following the guidance line and smoothness.\\
\indent
The spline optimization is within the linearized constraint. The constraints in QP speed optimization include the following boundary constraints:
\begin{equation}
 \begin{array}{cl}
 S(t_i) < S_(t_{i+1}), \, i=0,1,2,..., n-1,\\
 S_{l,t_i} \leq S(t_i) \leq S_{u,t_i},\\
 S'(t_i) \leq V_{upper}

 \end{array}
\end{equation}
as well as constraints for matching the initial velocity and acceleration. The first constraint is monotonicity evaluated at designated points. The second, third, and fourth constraints are requirements from traffic regulations and vehicle dynamic constraints. After wrapping up the cost objective and constraints, the spline solver will generate a smooth feasible speed profile as in Figure 2.13. Combined with the path profile, EM planner will generate a smooth trajectory for the control module.
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\linewidth]{2_13.png}
	\caption{Spline QP speed optimizer. [12]}
	\label{fig:2.13} 
\end{figure}

\subsection{Notes on Solving Quadratic Programming Problems}
For safety considerations, we evaluate the path and speed at approximately one-hundred different locations or time points. The number of constraints is greater than six hundred. For both the path and speed optimizers, we find that piecewise quintic polynomials are good enough. The spline generally contains 3 to 5 polynomials with approximately 30 parameters. Thus, the quadratic programming problem has a relatively small objective function but large number of constraints. Consequently, an active set QP solver is good for solving the problem. In addition to accelerating the quadratic programming, we use the result calculated in the last cycle as a hot start. The QP problem can be solved within 3 ms on average, which satisfies our time consumption requirement.

\section{Case Study}
Although most state-of-the-art planning algorithms are based on heavy decisions, EM planner is a light-decision-based planner. It is true that a heavy-decision-based algorithm, or heavily rule-based algorithm, is easily understood and explained. The disadvantages are also clear: it may be trapped in corner cases (while its frequency is closely related to the complexity and magnitude of the number of rules) and not always be optimal. In this section, we will illustrate the benefits of the light-decision-based planning algorithm by presenting several case studies. These cases were exposed during the intense daily test routines in Baidu’s heavy-decision planning modules and solved by the latest light-decision planning module.\\
\indent
Figure 2.14 is a hands-on example of how EM
planner iterates within and between planning cycles to achieve the optimal trajectory. In this case study, we demonstrate how the trajectory is generated while an obstacle enters our path. Assuming that the master vehicle has a speed of 10 meters per second and there is a dynamic obstacle that is moving toward us in the opposite direction with a speed that is also 10 meters per second, EM planner generates the path and speed profile iteratively with the steps below.
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\linewidth]{2_14.png}
	\caption{Case Study - Nudge oncoming dynamic obstacle This figure shows how the EM planner manages to iteratively solve the update path and speed profile. [12]}
	\label{fig:2.14} 
\end{figure}\\
\indent
1) Historical Planning (Figure 2.14a). In the historical planning profile, i.e., before the dynamic obstacle enters, the master vehicle
is moving forward straight with a constant
speed of 10 meters per second.\\
\indent
2) Path Profile Iteration 1 (Figure 2.14b). During this step, the speed profile is cruising at 10m/s from the historical profile. Based on this cursing speed, the master vehicle and the dynamic obstacle will meet each other at
position S = 40m. Consequently, the best
way to avoid this obstacle is to nudge it from the right side at S = 40m.\\
\indent
3) Speed Profile Iteration 1 (Figure 2.14c). Based on the path profile, which is nudge from the right, from step 1, the master vehicle adjusts its speed according to its interaction with the obstacle. Thus, the master vehicle will slow to 5 m/s when passing an obstacle with a slower speed, as passengers may expect.\\
\indent
4) Path Profile Iteration 2 (Figure 2.14d). Under the new speed profile, which is slower than
the original one, the master vehicle no longer passes the dynamic obstacle at S = 40m but rather a new position at S = 30m. Thus, the path to nudge the obstacle should be updated to a new one to maximize the nudge distance at S = 30m.\\
\indent
5) Speed Profile Iteration 2 (Figure 2.14e). Under the new path profile, where the nudge is performed at S = 30m, the slow down at S = 40m is no longer necessary. The new
speed profile indicates that the master vehicle can accelerate at S = 40m and still generate a smooth pass at S = 30m.\\
\indent
Thus, the final trajectory based on the four steps is to slow to nudge the obstacle at S=30 m and then accelerate after the master vehicle passes the obstacle, which is very likely how human drivers perform under this scenario.\\
\indent
Note that it is not necessary to always take
exactly four steps to create the plan. It could take
fewer or more steps depending on the scenario. In
general, the more complicated the environment is,
the more steps that may be required.
 \chapter{Working Outline}
 \section{Summary of Objectives}
 The aim of the thesis is to implement EM planner in the  AGV cars. For ego cars and AGV cars, we need to face different scenarios, so we need to find a suitable strategy to do it. Especially, due to the huge workload, we can focus on the scene of the intersection, or the scene of the crowd, or the scene of the elevator door.
 Finally, the response to which scenario depends on the demands of the company.
 \section{Work Plan}
 Fortunately, Baidu's apollo project is open source， We can directly read the source code of the EM planner section. This is the first step, then, the most impotant is how to apply it to the AGV cars.
 \chapter{Actual Work}
 During the summer internship last year, I have done some related work. The main steps is:\\
 \indent
 1) Taking sufficient sampling points in the feasible area. The sampling points refer to the target points in each planning cycle. The more sampling points, the more paths, and the longer sampling points, the longer paths. Sampling points need to be set reasonably. If too many, it will increase the calculation, and the calculation of the car is not enough, it will affect the performance of the car.\\
 \indent
 2) Calculating the cost for each trajectory and seting a suitable cost function. The cost function needs to consider the feasibility and safety of the trajectory.\\
 \indent
    \begin{figure}[ht]
 	\centering
 	\includegraphics[width=0.8\linewidth]{4_2.png}
 	\caption{Simulation result.}
 	\label{fig:4.1} 
 \end{figure}
 3) Cycle monitoring, each time the trajectory with the lowest cost is selected for collision detection and physical limit detection. Physical limit detection refers to if the car can follow this trajectory physically. If the speed or angular velocity or acceleration of the car is limited,  this trajectory can't be executed.\\
 \indent
 4) Returning the trajectory, then find the speed and angular velocity of this trajectory, and then give it to the control module for execution. The simulation result is shown in the figure 4.1.
 
 
 \addcontentsline{toc}{chapter}{Conclusion}
 
% % switch to A-B-C chaptering
% \appendix	
% 
% \chapter{Proof of theorem \ref{theo}}
% \label{sec:prooftheorem}
% 
 
 
 \addcontentsline{toc}{chapter}{Bibliography}
 \bibliographystyle{IEEEtran}
 
 \bibliography{../biblio.bib}
% \cite{DBLP:journals/corr/abs-1803-04868}
% \cite{inbook}
% \cite{583794}
% \cite{article}
% \cite{article5}
% \cite{7313361}
% \cite{article7}
% \cite{6f42273b120f421fa980c61913dcd489}
% \cite{4082128}
% \cite{article10}
% \cite{10.2307/2984875}
% \cite{DBLP:journals/corr/abs-1807-08048}
 
 
 
\end{document}
